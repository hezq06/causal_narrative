{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1924847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "# %matplotlib\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7076887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causal_narrative.fmriutil import *\n",
    "from causal_narrative.datautil import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c8f550",
   "metadata": {},
   "source": [
    "## Cross Layer Causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6a03d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_layer=3\n",
    "check_layer=8\n",
    "# model_type=\"opt-125m\"\n",
    "# model_type=\"opt-350m\"\n",
    "model_type=\"gpt2\"\n",
    "\n",
    "fu = FmriUtil()\n",
    "ndp = NarrativeDataPreprocess()\n",
    "resdict_l = []\n",
    "for ii_trial in tqdm_notebook(range(10)):\n",
    "    print(\"Trial number:\",ii_trial)\n",
    "    resdict={}\n",
    "    for task in ndp.tasks:\n",
    "        gptcodeall, gptcodeall_noise, noise_paral = fu.opt_encode_causalstudy(task=task, insert_layer=insert_layer, model_type=model_type)\n",
    "        resdict[task]=gptcodeall[check_layer,:,:], gptcodeall_noise[check_layer,:,:], noise_paral\n",
    "    resdict_l.append(resdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a55a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndp = NarrativeDataPreprocess()\n",
    "data_home = \"../dataset/narrative_encode\"\n",
    "opt_model = \"opt-125m_no_case\"\n",
    "# opt_model = \"opt-350m\"\n",
    "# opt_model = \"gpt2\"\n",
    "window = 128\n",
    "layer=insert_layer\n",
    "featurel = []\n",
    "for task in ndp.tasks:\n",
    "    mat = load_data(os.path.join(data_home, \"%s/opt_no_case_alignmat.pickle\" % task))\n",
    "    feature_all = load_data(\n",
    "        os.path.join(data_home, \"%s/learning_dynamics/opt_encode_%s_w%s.data\" % (task, opt_model, window)))\n",
    "#     mat = load_data(os.path.join(data_home, \"%s/opt_alignmat.pickle\" % task))\n",
    "#     mat = load_data(os.path.join(data_home, \"%s/gpt2_alignmat.pickle\" % task))\n",
    "#     feature_all = load_data(\n",
    "#         os.path.join(data_home, \"%s/opt_encode_%s_w%s.data\" % (task, opt_model, window)))\n",
    "    feature = feature_all[layer, :, :].type(torch.FloatTensor).numpy()\n",
    "    featurel.append(feature)\n",
    "feature_all3 = np.concatenate(featurel, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b8ce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pca3, pM3, V3 = pca_proj(feature_all3.T, 20)\n",
    "feature_pca3 = feature_pca3.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d5eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer=check_layer\n",
    "featurel = []\n",
    "for task in ndp.tasks:\n",
    "    mat = load_data(os.path.join(data_home, \"%s/opt_no_case_alignmat.pickle\" % task))\n",
    "    feature_all = load_data(\n",
    "        os.path.join(data_home, \"%s/learning_dynamics/opt_encode_%s_w%s.data\" % (task, opt_model, window)))\n",
    "#     mat = load_data(os.path.join(data_home, \"%s/opt_alignmat.pickle\" % task))\n",
    "#     mat = load_data(os.path.join(data_home, \"%s/gpt2_alignmat.pickle\" % task))\n",
    "#     feature_all = load_data(\n",
    "#         os.path.join(data_home, \"%s/opt_encode_%s_w%s.data\" % (task, opt_model, window)))\n",
    "    feature = feature_all[layer, :, :].type(torch.FloatTensor).numpy()\n",
    "    featurel.append(feature)\n",
    "feature_all8 = np.concatenate(featurel, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd23c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pca8, pM8, V8 = pca_proj(feature_all8.T, 20)\n",
    "feature_pca8 = feature_pca8.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01004815",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptcodeall_l = []\n",
    "gptcodeall_noise_l = []\n",
    "noise_all_l = []\n",
    "for resdict in resdict_l:\n",
    "    for key in resdict.keys():\n",
    "        gptcodeall, gptcodeall_noise, noise_paral = resdict[key]\n",
    "        noise_all = []\n",
    "        for para in noise_paral:\n",
    "            noise_all.append(para['add_noise'].numpy())\n",
    "        noise_all=np.array(noise_all)\n",
    "        gptcodeall_l.append(gptcodeall.numpy())\n",
    "        gptcodeall_noise_l.append(gptcodeall_noise.numpy())\n",
    "        noise_all_l.append(noise_all)\n",
    "gptcodeall_l = np.concatenate(gptcodeall_l,axis=0)\n",
    "gptcodeall_noise_l = np.concatenate(gptcodeall_noise_l,axis=0)\n",
    "noise_all_l = np.concatenate(noise_all_l,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397f65a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptcodeall_pca = gptcodeall_l.dot(pM8.T)\n",
    "gptcodeall_noise_pca = gptcodeall_noise_l.dot(pM8.T)\n",
    "diff_pca = gptcodeall_noise_pca-gptcodeall_pca\n",
    "\n",
    "noise_pca = noise_all_l.dot(pM3.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2cf5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, t_re = fit_linear(diff_pca[:,:], noise_pca[:,:])\n",
    "transformation_matrix, bias_vector = t_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7030cdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the matrix\n",
    "# plt.imshow(transformation_matrix.T, cmap='seismic')\n",
    "trasn_mat = transformation_matrix.T\n",
    "plt.imshow(np.abs(trasn_mat), cmap='OrRd', vmin=0.0, vmax=0.3)\n",
    "plt.xlabel(\"Layer 9 indexes\",size=12)\n",
    "plt.ylabel(\"Layer 4 indexes\",size=12)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c41e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "thred = np.median(np.abs(trasn_mat))\n",
    "thred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9e8c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_mat = np.zeros((20,20))\n",
    "for ii in range(20):\n",
    "    for jj in range(20):\n",
    "        if np.abs(trasn_mat)[ii,jj]>thred:\n",
    "            cause_mat[ii,jj]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df3672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the matrix\n",
    "plt.imshow(cause_mat, cmap='seismic', vmin=-1.5, vmax=1.5)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb4845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sinkdeg = np.sum(cause_mat, axis=0)\n",
    "sinkdeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f91cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = np.argsort(sinkdeg)\n",
    "sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581b23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_index = [0,  2,  1,  6,  7,  3, 17, 10,  4,  8]\n",
    "top_index = [15, 12, 19,  5, 14, 18, 16, 9, 11, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81b1667",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer=check_layer\n",
    "\n",
    "for task in ndp.tasks:\n",
    "#     mat = load_data(os.path.join(data_home, \"%s/opt_no_case_alignmat.pickle\" % task))\n",
    "#     feature_all = load_data(\n",
    "#         os.path.join(data_home, \"%s/learning_dynamics/opt_encode_%s_w%s.data\" % (task, opt_model, window)))\n",
    "#     mat = load_data(os.path.join(data_home, \"%s/opt_alignmat.pickle\" % task))\n",
    "    mat = load_data(os.path.join(data_home, \"%s/gpt2_alignmat.pickle\" % task))\n",
    "    feature_all = load_data(\n",
    "        os.path.join(data_home, \"%s/opt_encode_%s_w%s.data\" % (task, opt_model, window)))\n",
    "    feature= feature_all[layer, :, :].type(torch.FloatTensor).numpy()\n",
    "    \n",
    "    feature_pca = feature.dot(pM8.T)\n",
    "    feature_pick = feature_pca[:,top_index]\n",
    "    \n",
    "    feature_alg = mat.T.dot(feature_pick)\n",
    "\n",
    "    zero_mask = (feature_alg != 0)[:, 0]\n",
    "    zero_feature = ((feature_alg == 0)[:, 0]).astype(int).reshape(-1, 1)\n",
    "    zero_feature = scipy.stats.zscore(zero_feature)\n",
    "    \n",
    "    feature_alg[zero_mask, :] = scipy.stats.zscore(feature_alg[zero_mask, :])\n",
    "    feature_alg_zero = np.concatenate([zero_feature, feature_alg], axis=-1)\n",
    "    feature_alg_zero = scipy.stats.zscore(feature_alg_zero)  # mat_pca_zscoresep # not big deal\n",
    "    save_data((feature_alg_zero, zero_mask), \n",
    "              os.path.join(data_home, \"%s/multilayer_4c9_gpt2_top/opt_encode_%s_l%s.data\" % (task, opt_model, layer)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:causal] *",
   "language": "python",
   "name": "conda-env-causal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
